# configs/fed.yaml

# 1. 数据路径 (与 local.yaml 保持一致)
data:
  office_home_root: "/data1/lc/data/office_home"
  domainnet_root: "/data1/lc/data/domainnet" # 用于 Unseen 测试 (Phase 2)

# 2. 联邦训练全局参数
train:
  # === 联邦核心参数 ===
  strategy: "fedavg" # 核心开关: 'fedavg' (基线) | 'ours' (你的算法)
  rounds: 1 # One-shot FL
  epochs_per_round: 20 # 每轮客户端在本地练多久 小数据集多跑几次

  # === 优化器参数 (保持与 local.yaml 一致) ===
  model_name: "/data1/lc/models/clip-vit-b32"
  batch_size: 32 # 显存够可以开大
  learning_rate: 1.0e-4
  weight_decay: 0.01
  fp16: true
  device: "cuda:3"

  # === 你的算法超参 ===
  temperature: 0.1 # 谱分数 Softmax 的温度系数，越小区分度越大 FedAvg 不用这个，但留着不报错

# 3. LoRA 设置 (保持与 local.yaml 一致)
lora:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: ["q_proj", "v_proj", "k_proj"]

# 4. 客户端配置 (Phase 3 关键)
# 这里的 malicious 开关决定了是否进行"语义攻击"
clients:
  - domain: "Art"
    malicious: false
  - domain: "Clipart"
    malicious: false
  - domain: "Product"
    malicious: false
  - domain: "Real_World" # 假设我们把 Real_World 设为坏人
    malicious: true
    data_ratio: 0.5 # 不生效
